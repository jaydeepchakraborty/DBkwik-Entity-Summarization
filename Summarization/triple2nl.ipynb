{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import nltk, inflect, re, string, os\n",
    "import simplejson as json\n",
    "import nl_helpers\n",
    "import shutil\n",
    "%run nl_helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# https://pypi.python.org/pypi/inflect\n",
    "p = inflect.engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EC2_URI = 'http://ec2-18-188-197-36.us-east-2.compute.amazonaws.com:3030/dbkwik/query'\n",
    "URI = 'http://dbkwik.webdatacommons.org/HarryPotter/resource/Harry_Potter'\n",
    "# URI = 'http://dbkwik.webdatacommons.org/Game_of_Thrones_Wik/resource/Daenerys_Targaryen'\n",
    "# URI = 'http://dbkwik.webdatacommons.org/GTA_Wik/resource/Russia'\n",
    "# URI = 'http://dbkwik.webdatacommons.org/Game_of_Thrones_Wik/resource/Jon_Snow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_hyphen_with_space(string):\n",
    "    return string.replace('_', ' ')\n",
=======
    "#########Module-1 : it will read all the test data and will create directory for each test data.\n",
    "##################  In next modules, We will store all the information i.e. triples associated  \n",
    "##################  with it, it's basic info and top k(10) triples (in json format) in these \n",
    "##################  directories.   \n",
>>>>>>> 36685338c5bcd5a5770395de0d4ef7abf4c1a952
    "\n",
    "#reading all the subjects (from sample test file)\n",
    "subj_directory = {}\n",
    "with open('test_subj.dat') as f:\n",
    "    URIs = f.readlines()\n",
    "    for uri in URIs:\n",
    "        directory = 'resources/' + uri.rstrip('\\n').split('/')[-1]\n",
    "        if os.path.exists(directory):\n",
    "            shutil.rmtree(directory)\n",
    "            os.makedirs(directory)\n",
    "            subj_directory[uri.rstrip('\\n')] = directory\n",
    "        else:\n",
    "            os.makedirs(directory)\n",
    "            subj_directory[uri.rstrip('\\n')] = directory\n",
    "\n",
    "#Persists all resources with directory info\n",
    "outfile = open('resource_directory.json', \"w\")\n",
    "outfile.write(json.dumps(subj_directory, indent=4, sort_keys=True))\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
=======
<<<<<<< HEAD
   "execution_count": 73,
=======
   "execution_count": 75,
>>>>>>> 36685338c5bcd5a5770395de0d4ef7abf4c1a952
>>>>>>> 003962e7cb0f9c3a268dcfe3e46882f18fec4977
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#########Module-2 : it will read all the test data and will fetch all the triples associated with it.\n",
    "##################  and save the information in all_triples.json in each corresponding directories.\n",
    "\n",
    "subj_directory = {}\n",
    "with open('resource_directory.json') as f:\n",
    "    subj_directory = json.load(f)\n",
    "\n",
    "for uri, directory in subj_directory.items():\n",
    "    #Fetching all triples for subject(URI)\n",
    "    all_triples = nl_helpers.get_all_triples(uri);\n",
    "    #Persists all triples for subject(URI)\n",
    "    outfile = open(directory+'/all_triples.json', \"w\")\n",
    "    outfile.write(json.dumps(all_triples, indent=4, sort_keys=True))\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
=======
<<<<<<< HEAD
   "execution_count": 74,
=======
   "execution_count": 76,
>>>>>>> 36685338c5bcd5a5770395de0d4ef7abf4c1a952
>>>>>>> 003962e7cb0f9c3a268dcfe3e46882f18fec4977
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
<<<<<<< HEAD
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT (group_concat(?type;separator='|') as ?types) ?name ?gender ?dbr WHERE {        \n",
      "        # Get Types of URI\n",
      "        <http://dbkwik.webdatacommons.org/HarryPotter/resource/Harry_Potter> rdf:type ?type .\n",
      "        FILTER(contains(str(?type), 'http://dbkwik.webdatacommons.org/HarryPotter/ontology')) .\n",
      "        \n",
      "        # Get English label of URI\n",
      "        OPTIONAL { <http://dbkwik.webdatacommons.org/HarryPotter/resource/Harry_Potter> <http://dbkwik.webdatacommons.org/HarryPotter/property/name> ?name . FILTER(lang(?name)='en') . }\n",
      "        OPTIONAL { <http://dbkwik.webdatacommons.org/HarryPotter/resource/Harry_Potter> <http://www.w3.org/2004/02/skos/core#prefLabel> ?name . FILTER(lang(?name)='en') . }\n",
      "        OPTIONAL { <http://dbkwik.webdatacommons.org/HarryPotter/resource/Harry_Potter> <http://www.w3.org/2000/01/rdf-schema#label> ?name . FILTER(lang(?name)='en') . }        \n",
      "                \n",
      "        # Try to get gender\n",
      "        OPTIONAL { <http://dbkwik.webdatacommons.org/HarryPotter/resource/Harry_Potter> <http://dbkwik.webdatacommons.org/HarryPotter/property/gender> ?gender . }\n",
      "        \n",
      "        # Try to get corresponding DBpedia Resource\n",
      "        OPTIONAL { <http://dbkwik.webdatacommons.org/HarryPotter/resource/Harry_Potter> owl:sameAs ?dbr . }\n",
      "    }\n",
      "    \n",
      "{'types': {'type': 'literal', 'value': 'http://dbkwik.webdatacommons.org/HarryPotter/ontology/Actor|http://dbkwik.webdatacommons.org/HarryPotter/ontology/Agent|http://dbkwik.webdatacommons.org/HarryPotter/ontology/Artist|http://dbkwik.webdatacommons.org/HarryPotter/ontology/Person'}, 'name': {'type': 'literal', 'xml:lang': 'en', 'value': 'Harry James Potter'}, 'gender': {'type': 'literal', 'xml:lang': 'en', 'value': 'Male'}, 'dbr': {'type': 'uri', 'value': 'http://dbpedia.org/resource/Harry_Potter'}}\n"
     ]
    }
   ],
=======
   "outputs": [],
>>>>>>> 36685338c5bcd5a5770395de0d4ef7abf4c1a952
   "source": [
    "#########Module-3 : it will read all the test data and will fetch first k triples associated with it.\n",
    "##################  it will also fetch the basic information of the subject \n",
    "##################  and save the information in k_triples.json in each corresponding directories.\n",
    "\n",
    "subj_directory = {}\n",
    "with open('resource_directory.json') as f:\n",
    "    subj_directory = json.load(f)\n",
    "\n",
    "for uri, directory in subj_directory.items():\n",
    "    #Read all triples for subject(URI) from JSON file\n",
    "    all_triples = {}\n",
    "    with open(directory + '/all_triples.json') as f:\n",
    "        all_triples = json.load(f)\n",
    "        #Fetching URI : to fetch basic-info,\n",
    "        subj_basic_info = nl_helpers.get_basic_info(uri)\n",
    "        #Fetching top k triples;all_triples: to fetch predicate-info and object-info, k = 10\n",
    "        pred_info = nl_helpers.get_top_k_triples(subj_basic_info['name'], all_triples , 10);\n",
    "        subj_info = {\n",
    "        'subj_basic_info': subj_basic_info,\n",
    "        'pred_info': pred_info\n",
    "        } \n",
    "        \n",
    "        #Persists k triples for subject(URI)\n",
    "        outfile = open(directory+'/k_triples.json', \"w\")\n",
    "        outfile.write(json.dumps(subj_info, indent=4, sort_keys=True))\n",
    "        outfile.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======
<<<<<<< HEAD
   "execution_count": 75,
=======
   "execution_count": 77,
>>>>>>> 36685338c5bcd5a5770395de0d4ef7abf4c1a952
>>>>>>> 003962e7cb0f9c3a268dcfe3e46882f18fec4977
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
<<<<<<< HEAD
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-a057a6567db0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mk_triples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_triples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/k_triples.dat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jaydeep/jaydeep_workstation/ScalaWS/DBKwikEntitySummarization/Summarization/nl_helpers.py\u001b[0m in \u001b[0;36mgenerate_summary\u001b[0;34m(k_triples)\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0mpredicate_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mpos_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pred_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicate_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicate_object\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'resources'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpredicate_object\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'r_resources'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicate_object\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'resources'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jaydeep/jaydeep_workstation/ScalaWS/DBKwikEntitySummarization/Summarization/nl_helpers.py\u001b[0m in \u001b[0;36mget_pred_pos_tag\u001b[0;34m(subj_nm, pred_nm, objs)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;31m# print(objs[index])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mpos_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubj_nm\u001b[0m  \u001b[0;34m,\u001b[0m \u001b[0mpred_nm\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpred_pos_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mpred_pos_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_pos_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[0;34m(tokens, tagset)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \"\"\"\n\u001b[1;32m    110\u001b[0m     \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36m_pos_tag\u001b[0;34m(tokens, tagset, tagger)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0mtagged_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mtagged_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en-ptb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtagged_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/nltk/tag/perceptron.py\u001b[0m in \u001b[0;36mtag\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTART\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/nltk/tag/perceptron.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTART\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/nltk/tag/perceptron.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m'!YEAR'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m'!DIGITS'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
=======
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "\n",
      "    SELECT ?p ?p_label ?o ?rank ?reverse {\n",
      "\n",
      "        {<http://dbkwik.webdatacommons.org/HarryPotter/resource/Harry_Potter> ?p ?o . BIND(false as ?reverse)} UNION {?o ?p <http://dbkwik.webdatacommons.org/HarryPotter/resource/Harry_Potter> . BIND(true as ?reverse)}\n",
      "                \n",
      "        FILTER (?p NOT IN (\n",
      "            <http://purl.org/dc/terms/subject>, \n",
      "            <http://xmlns.com/foaf/0.1/depiction>, \n",
      "            <http://www.w3.org/2002/07/owl#sameAs>, \n",
      "            <http://dbkwik.webdatacommons.org/HarryPotter/ontology/thumbnail>, \n",
      "            <http://dbkwik.webdatacommons.org/HarryPotter/property/predecessor>,\n",
      "            <http://dbkwik.webdatacommons.org/HarryPotter/property/successor>, \n",
      "            <http://dbkwik.webdatacommons.org/HarryPotter/property/name>, \n",
      "            <http://dbkwik.webdatacommons.org/HarryPotter/property/gender>, \n",
      "            <http://xmlns.com/foaf/0.1/isPrimaryTopicOf>, \n",
      "            <http://xmlns.com/foaf/0.1/primaryTopic>                    \n",
      "        )) .\n",
      "        \n",
      "        ?p <http://www.w3.org/2000/01/rdf-schema#label> ?p_label .\n",
      "        FILTER(lang(?p_label)='en') .\n",
      "                \n",
      "        OPTIONAL { <http://dbkwik.webdatacommons.org/HarryPotter/resource/Harry_Potter> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> ?class . ?p ?class ?prop_rank }\n",
      "        OPTIONAL { ?p <http://purl.org/voc/vrank#proprank> ?prop_rank }\n",
      "        OPTIONAL { ?o <http://purl.org/voc/vrank#pagerank> ?obj_rank }\n",
      "        OPTIONAL {FILTER ISLITERAL(?o) . BIND(0.15 as ?obj_rank) }        \n",
      "        \n",
      "        #BIND(?obj_rank * ?prop_rank as ?rank) # PROD RANK\n",
      "        BIND(?obj_rank * ?prop_rank / (?obj_rank + ?prop_rank) as ?rank) # HARMONIC RANK\n",
      "    } GROUP BY ?o ?p ?p_label ?rank ?reverse ORDER BY DESC(?rank)    \n",
      "    \n"
=======
      "Scuderia Ferrari is a formula 1 team, an organisation and a sports team. \n"
>>>>>>> 36685338c5bcd5a5770395de0d4ef7abf4c1a952
>>>>>>> 003962e7cb0f9c3a268dcfe3e46882f18fec4977
     ]
    }
   ],
   "source": [
    "#########Module-4 : it will read all the test data and it's all information from the json file(k_triples.json).\n",
    "##################  from that information it will generate summary and save in each corresponding directories. \n",
    "##################  and save the information in k_triples.json in each corresponding directories.\n",
    "\n",
    "subj_directory = {}\n",
    "with open('resource_directory.json') as f:\n",
    "    subj_directory = json.load(f)\n",
    "\n",
    "for uri, directory in subj_directory.items():\n",
    "    summary = ''\n",
    "\n",
    "    k_triples = {}\n",
    "    with open(directory+'/k_triples.json') as f:\n",
    "        k_triples = json.load(f)\n",
    "\n",
    "    summary = generate_summary(k_triples)\n",
    "    f=open(directory+'/k_triples.dat', \"w+\")\n",
    "    f.write(summary)\n",
    "    f.close()\n",
    "    print(summary)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
